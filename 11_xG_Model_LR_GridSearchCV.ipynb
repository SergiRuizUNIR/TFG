{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.metrics import log_loss, roc_auc_score, roc_curve, make_scorer, brier_score_loss\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "from joblib import dump, load\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metric for comparison: McFadden's Pseudo R-Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcfadden_r2(y, y_pred):\n",
    "    ll = log_loss(y, y_pred)\n",
    "    ll_null = log_loss(y, np.full(len(y), y.mean()))\n",
    "    return 1 - (ll/ll_null)\n",
    "pseudo_r2_scorer = make_scorer(mcfadden_r2, needs_proba=True, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'roc_aug': 'roc_auc', 'mcfaddens_r2': pseudo_r2_scorer}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "df = pd.read_parquet(os.path.join(cwd, 'data', 'shots.parquet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop first the columns without any information useful such as id's and names. Also drop columns for logistic regression. LR does not deal well with dependent features such as X and Y as we will use use the distance/ angle features capture these location features instead. Same problem for features with columns with missing data (the ones that come from StatsBomb only).\n",
    "Split data in penalty and non-penalty shots and subset dataset for logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['x', 'y','match_id', 'statsbomb_id', 'statsbomb_team_id', 'player_id_statsbomb', 'competition_gender', 'team_name',\n",
    "         'player_id', 'firstName', 'middleName', 'lastName', 'Name', 'dataset', 'wyscout_id', 'wyscout_team_id', 'team_id',\n",
    "         'player_id_wyscout','competition_name','minute','shot_zone','match_week','pass_end_y',\n",
    "         'goalkeeper_x', 'goalkeeper_y', 'carry_length', 'shot_one_on_one', 'shot_open_goal','under_pressure', 'area_shot', \n",
    "         'area_goal', 'n_angle', 'smart_pass','pass_end_x'], axis=1, inplace=True)\n",
    "mask_penalty = (df.shot_type_name=='penalty')\n",
    "df_penalty = df[mask_penalty].copy()\n",
    "df_penalty.drop(['visible_angle','middle_angle','distance_to_goal','distance_visible_angle','log_distance_to_goal',\n",
    "                 'assist_type', 'pass_switch', 'pass_cross', 'pass_cut_back','counter_attack', 'pass_height_name',\n",
    "                 'pass_technique_name', 'shot_zone_number','shot_zone_player_number','fast_break', 'strong_foot',\n",
    "                 'body_part_name','shot_type_name'], axis=1, inplace=True)\n",
    "df_non_penalty = df[~mask_penalty].copy()\n",
    "X_penalty = df_penalty.drop('goal', axis=1)\n",
    "y_penalty = df_penalty.goal\n",
    "X = df_non_penalty.drop('goal', axis=1)\n",
    "y = df_non_penalty.goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42, stratify=y)\n",
    "X_penalty_train, X_penalty_test, y_penalty_train, y_penalty_test = train_test_split(X_penalty, y_penalty,\n",
    "                                                                        train_size=0.8, random_state=42, stratify=y_penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset for logistic regession into passes / other assists. They have diferent columns of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(X, y):\n",
    "    mask = X.assist_type == 'pass'\n",
    "    X_pass = X[mask].drop('assist_type', axis=1).copy()\n",
    "    y_pass = y[mask]\n",
    "    X_other = X[~mask].dropna(axis=1, how='all').copy()\n",
    "    y_other = y[~mask]\n",
    "    return X_pass, y_pass, X_other, y_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pass, y_train_pass, X_train_other, y_train_other = split(X_train, y_train)\n",
    "X_test_pass, y_test_pass, X_test_other, y_test_other = split(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline for cleaning pass assists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['competition_type','competition_part','H_A_column','match_moment','shot_type_name', 'body_part_name',\n",
    "        'pass_technique_name', 'pass_height_name']\n",
    "cats = [['League', 'Cup'],\n",
    "        ['start', 'middle', 'final', 'group', 'knockout'],\n",
    "        ['Home Team', 'Away Team'],\n",
    "        ['0-15','15-30','30-45','45-60','60-75','75-90'],\n",
    "        ['open_play', 'corner', 'throw_in', 'free_kick'],\n",
    "        ['Right Foot', 'Left Foot', 'Other'],\n",
    "        ['other', 'Outswinging', 'Through Ball', 'Inswinging', 'Straight'],\n",
    "        ['Ground/ Low Pass', 'High Pass']]\n",
    "pass_one_hot = ColumnTransformer([('encoder', OneHotEncoder(drop='first', categories=cats), cols)], remainder='passthrough')\n",
    "pipe_pass = Pipeline([('one_hot', pass_one_hot),\n",
    "                      ('impute', SimpleImputer()),\n",
    "                      ('scale', StandardScaler()),\n",
    "                      ('lr', LogisticRegression(random_state=42))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column names of transformed pass data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_cols_remain = [col for col in X_train_pass.columns if col not in cols]\n",
    "new_cols_pass = [item for sublist in cats for i, item in enumerate(sublist) if (i>0)]\n",
    "new_cols_pass.extend(original_cols_remain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline for cleaning other assists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting direct to recovery so does not not encoded twice ( also covered by shot_type_name == 'direct_set_piece')\n",
    "X_train_other.loc[X_train_other.assist_type == 'direct', 'assist_type'] = 'recovery'\n",
    "X_test_other.loc[X_test_other.assist_type == 'direct', 'assist_type'] = 'recovery'\n",
    "\n",
    "cols = ['competition_type','competition_part','H_A_column','match_moment','shot_type_name', 'body_part_name', 'assist_type']\n",
    "cats = [['League', 'Cup'],\n",
    "        ['start', 'middle', 'final', 'group', 'knockout'],\n",
    "        ['Home Team', 'Away Team'],\n",
    "        ['0-15','15-30','30-45','45-60','60-75','75-90'],\n",
    "        ['free_kick', 'direct_set_piece', 'corner', 'open_play', 'throw_in'],\n",
    "        ['Other', 'Right Foot', 'Left Foot'],\n",
    "        ['rebound', 'recovery', 'clearance']]\n",
    "other_one_hot = ColumnTransformer([('encoder', OneHotEncoder(drop='first', categories=cats), cols)], remainder='passthrough')\n",
    "pipe_other = Pipeline([('one_hot', other_one_hot),\n",
    "                       ('impute', SimpleImputer()),\n",
    "                       ('scale', StandardScaler()),\n",
    "                       ('lr', LogisticRegression(random_state=42))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column names of transformed passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "original_cols_remain = [col for col in X_train_other.columns if col not in cols]\n",
    "new_cols_other = [item for sublist in cats for i, item in enumerate(sublist) if (i>0)]\n",
    "new_cols_other.extend(original_cols_remain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline for cleaning penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['competition_type','competition_part','H_A_column','match_moment']\n",
    "cats = [['League', 'Cup'],\n",
    "        ['start', 'middle', 'final', 'group', 'knockout'],\n",
    "        ['Home Team', 'Away Team'],\n",
    "        ['0-15','15-30','30-45','45-60','60-75','75-90']]\n",
    "penalty_one_hot = ColumnTransformer([('encoder', OneHotEncoder(drop='first', categories=cats), cols)], remainder='passthrough')\n",
    "pipe_penalty = Pipeline([('one_hot', penalty_one_hot),\n",
    "                      ('impute', SimpleImputer()),\n",
    "                      ('scale', StandardScaler()),\n",
    "                      ('lr', LogisticRegression(random_state=42))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column names of transformed penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_cols_remain = [col for col in X_penalty_train.columns if col not in cols]\n",
    "new_cols_penalties = [item for sublist in cats for i, item in enumerate(sublist) if (i>0)]\n",
    "new_cols_penalties.extend(original_cols_remain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search parameters for gridsearchcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'lr__C': np.logspace(-3, 0.1, 100)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the inner grid search for shots assisted by passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pass = GridSearchCV(estimator=pipe_pass, param_grid=param_grid, scoring='neg_log_loss', n_jobs=-1)\n",
    "clf_pass.fit(X_train_pass, y_train_pass)\n",
    "lr = clf_pass.best_estimator_.named_steps['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-49adc006e442>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnested_score_pass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf_pass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train_pass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train_pass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ROC AUC for shots assisted by passes:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnested_score_pass\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_roc_aug'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"McFadden's Pseudo R-squared shots assisted by passes:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnested_score_pass\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_mcfaddens_r2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\xGenv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\xGenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 248\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\xGenv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\xGenv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\xGenv\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\xGenv\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    433\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\xGenv\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n"
     ]
    }
   ],
   "source": [
    "nested_score_pass = cross_validate(clf_pass, X=X_train_pass, y=y_train_pass, scoring=scoring, n_jobs=-1)\n",
    "print('ROC AUC for shots assisted by passes:', nested_score_pass['test_roc_aug'].mean())\n",
    "print(\"McFadden's Pseudo R-squared shots assisted by passes:\", nested_score_pass['test_mcfaddens_r2'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the inner grid search for shots assisted other than passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_other = GridSearchCV(estimator=pipe_other, param_grid=param_grid, scoring='neg_log_loss', n_jobs=-1)\n",
    "clf_other.fit(X_train_other, y_train_other)\n",
    "nested_score_other = cross_validate(clf_other, X=X_train_other, y=y_train_other, scoring=scoring, n_jobs=-1)\n",
    "print('ROC AUC for other model:', nested_score_other['test_roc_aug'].mean())\n",
    "print(\"McFadden's Pseudo R-squared for other model:\", nested_score_other['test_mcfaddens_r2'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the inner grid search for penalty shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "clf_penalty = GridSearchCV(estimator=pipe_penalty, param_grid=param_grid, scoring='neg_log_loss', n_jobs=-1)\n",
    "clf_penalty.fit(X_penalty_train, y_penalty_train)\n",
    "nested_score_penalty = cross_validate(clf_penalty, X=X_penalty_train, y=y_penalty_train, scoring=scoring, n_jobs=-1)\n",
    "print('ROC AUC for penalty model:', nested_score_penalty['test_roc_aug'].mean())\n",
    "print(\"McFadden's Pseudo R-squared for penalty:\", nested_score_penalty['test_mcfaddens_r2'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr_pass = clf_pass.predict_proba(X_test_pass)\n",
    "y_pred_lr_other = clf_other.predict_proba(X_test_other)\n",
    "y_pred_lr = np.concatenate([y_pred_lr_pass, y_pred_lr_other])\n",
    "y_true_test = np.concatenate([y_test_pass, y_test_other])\n",
    "fraction_of_positives_lr, mean_predicted_value_lr = calibration_curve(y_true_test, y_pred_lr[:, 1], n_bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot calibration curve on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')\n",
    "fig = plt.figure(constrained_layout=True, figsize=(10, 15))\n",
    "gs = fig.add_gridspec(ncols=1, nrows=2, height_ratios=(2/3, 1/3))\n",
    "ax1 = fig.add_subplot(gs[0])\n",
    "ax1.plot(mean_predicted_value_lr, fraction_of_positives_lr, \"-o\", color='#dbdf4a', label='Logistic regression')\n",
    "ax1.plot([0, 1], [0, 1], \"--\", color='#e7aeca', label=\"Perfectly calibrated\")\n",
    "ax1.set_xlabel('Mean predicted value', fontsize=15)\n",
    "ax1.set_ylabel('Fraction of positives', fontsize=15)\n",
    "ax1.set_title('Calibration curve', fontsize=20, pad=10)\n",
    "ax1.legend(fontsize=15)\n",
    "ax1.tick_params(labelsize=15)\n",
    "ax2 = fig.add_subplot(gs[1])\n",
    "sns.distplot(y_pred_lr[:, 1], color='#4fe4e4', label='Logistic regression', kde=False, ax=ax2)\n",
    "ax2.set_xlabel('Predicted value', fontsize=15)\n",
    "ax2.set_ylabel('Count', fontsize=15)\n",
    "ax2.tick_params(labelsize=15)\n",
    "ax2.legend(fontsize=15)\n",
    "ax2.set_title('Distribution of predictions', fontsize=20, pad=10);\n",
    "fig.savefig(os.path.join(cwd, 'figures', '22_calibration_curve.png'), bbox_inches = 'tight', pad_inches = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The log loss of the model with Random Search is: \" + str(log_loss(y_true_test, y_pred_lr)))\n",
    "print(\"The ROC AUC score of the model with Random Search is: \" +str(roc_auc_score(y_true_test, y_pred_lr[:,1])))\n",
    "print('Pseudo R-squared, logistic regression:', mcfadden_r2(y_true_test, y_pred_lr[:,1]))\n",
    "print('Brier score, logistic regression:',brier_score_loss(y_true_test, y_pred_lr[:,1], pos_label=y_true_test.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr_p = clf_penalty.predict_proba(X_penalty_test)\n",
    "y_true_test_p = y_penalty_test\n",
    "fraction_of_positives_lr_p, mean_predicted_value_lr_p = calibration_curve(y_true_test_p, y_pred_lr_p[:, 1], n_bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout=True, figsize=(10, 15))\n",
    "gs = fig.add_gridspec(ncols=1, nrows=2, height_ratios=(2/3, 1/3))\n",
    "ax1 = fig.add_subplot(gs[0])\n",
    "ax1.plot(mean_predicted_value_lr_p, fraction_of_positives_lr_p, \"-o\", color='#dbdf4a', label='Logistic regression')\n",
    "ax1.plot([0, 1], [0, 1], \"--\", color='#e7aeca', label=\"Perfectly calibrated\")\n",
    "ax1.set_xlabel('Mean predicted value', fontsize=15)\n",
    "ax1.set_ylabel('Fraction of positives', fontsize=15)\n",
    "ax1.set_title('Calibration curve', fontsize=20, pad=10)\n",
    "ax1.legend(fontsize=15)\n",
    "ax1.tick_params(labelsize=15)\n",
    "ax2 = fig.add_subplot(gs[1])\n",
    "sns.distplot(y_pred_lr_p[:, 1], color='#4fe4e4', label='Logistic regression', kde=False, ax=ax2)\n",
    "ax2.set_xlabel('Predicted value', fontsize=15)\n",
    "ax2.set_ylabel('Count', fontsize=15)\n",
    "ax2.tick_params(labelsize=15)\n",
    "ax2.legend(fontsize=15)\n",
    "ax2.set_title('Distribution of predictions', fontsize=20, pad=10);\n",
    "fig.savefig(os.path.join(cwd, 'figures', '22_calibration_curve.png'), bbox_inches = 'tight', pad_inches = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The log loss of the model with Random Search is: \" + str(log_loss(y_true_test_p, y_pred_lr_p)))\n",
    "print(\"The ROC AUC score of the model with Random Search is: \" +str(roc_auc_score(y_true_test_p, y_pred_lr_p[:,1])))\n",
    "print('Pseudo R-squared, logistic regression:', mcfadden_r2(y_true_test_p, y_pred_lr_p[:,1]))\n",
    "print('Brier score, logistic regression:',brier_score_loss(y_true_test_p, y_pred_lr_p[:,1], pos_label=y_true_test_p.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(clf_pass.best_estimator_, os.path.join(cwd, 'models', 'lr_pass.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(clf_other.best_estimator_, os.path.join(cwd, 'models', 'lr_other.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(clf_penalty.best_estimator_, os.path.join(cwd, 'models', 'lr_penalty.joblib'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reload shot dataset for ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(os.path.join(cwd, 'data', 'shots.parquet'))\n",
    "df = df[['match_id', 'wyscout_id', 'statsbomb_id']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_other['goal'] = y_train_other\n",
    "X_train_other['split'] = 'train'\n",
    "X_test_other['goal'] = y_test_other\n",
    "X_test_other['split'] = 'test'\n",
    "df_other = pd.concat([X_train_other, X_test_other])\n",
    "df_other = df_other.merge(df, left_index=True, right_index=True, validate='1:1', how='left')\n",
    "df_other.reset_index(drop=True, inplace=True)\n",
    "df_other.to_parquet(os.path.join(cwd, 'data', 'modelling', 'lr_other.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pass['goal'] = y_train_pass\n",
    "X_train_pass['split'] = 'train'\n",
    "X_test_pass['goal'] = y_test_pass\n",
    "X_test_pass['split'] = 'test'\n",
    "df_pass = pd.concat([X_train_pass, X_test_pass])\n",
    "df_pass = df_pass.merge(df, left_index=True, right_index=True, validate='1:1', how='left')\n",
    "df_pass.reset_index(drop=True, inplace=True)\n",
    "df_pass.to_parquet(os.path.join(cwd, 'data', 'modelling', 'lr_pass.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_penalty_train['goal'] = y_penalty_train\n",
    "X_penalty_train['split'] = 'train'\n",
    "X_penalty_test['goal'] = y_penalty_test\n",
    "X_penalty_test['split'] = 'test'\n",
    "df_penalty = pd.concat([X_penalty_train, X_penalty_test])\n",
    "df_penalty = df_penalty.merge(df, left_index=True, right_index=True, validate='1:1', how='left')\n",
    "df_penalty.reset_index(drop=True, inplace=True)\n",
    "df_penalty.to_parquet(os.path.join(cwd, 'data', 'modelling', 'lr_penalty.parquet'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xGenv",
   "language": "python",
   "name": "xgenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
